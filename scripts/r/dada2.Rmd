---
title: "Dada2_report"
author: "Ram√≥n Gallego"
date: "1/9/2018"
output: html_document
params:
  folder:
    value: x

---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir=params$folder)
```

## Dada2 report

You have successfully split your libraries into a pair (or two) of fastq files per sample. Now let's import the output of demultiplex_both_fastq.sh  

First load the packages. And let's update the parameters we need
```{r loading packages, echo=FALSE ,message=FALSE}
library(devtools)
library(tidyverse)
library(stringr)
library (dada2)
library (Biostrings)

#fastq.folder="/Users/rgallego/fastqs_demultiplexed_for_DADA2/demultiplexed_20180108_1539"
sample.map<-read_delim(paste0(fastq.folder,"/sample_trans.tmp"),col_names = c("Full_Id", "fastq_header","Sample"),delim = "\t")
head (sample.map)

path1= paste0(params$folder,"/demultiplexed")
#path1= "/Users/rgallego/fastqs_demultiplexed_for_DADA2/demultiplexed_20180108_1539"
```

Firstly, we'll find the patterns that separate our Fwd, Rev, .1 and .2 files. look at the quality of the .1 and .2 reads
```{r listing files}

F1s <- sort(list.files(path1, pattern="_Fwd.1.fastq", full.names = TRUE))
F2s <- sort(list.files(path1, pattern="_Fwd.2.fastq", full.names = TRUE))
R1s <- sort(list.files(path1, pattern="_Rev.1.fastq", full.names = TRUE))
R2s <- sort(list.files(path1, pattern="_Rev.2.fastq", full.names = TRUE))

# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- str_replace(basename(F1s), "_Fwd.1.fastq","")

#Now use only those that reflect a real sample

good.sample.names<-sample.names[sample.names %in% sample.map$fastq_header]
# Introduce here the biological counterpart of the fastq file
map_sample[,3][match(map_otu[,2], map_sample[,1])]
real.sample.name <- sample.map[,3][match(good.sample.names,sample.map$fastq_header),1]
  
# Now subset the number of files to be looked at
  
F1sgood<-F1s[sample.names %in% sample.map$fastq_header]
F2sgood<-F2s[sample.names %in% sample.map$fastq_header]
R1sgood<-R1s[sample.names %in% sample.map$fastq_header]
R2sgood<-R2s[sample.names %in% sample.map$fastq_header]

```

A nice idea is to plot the Quality of the F1 reads

```{r qplot1, echo=FALSE}
plotQualityProfile(F1sgood[1:4])
```

The quality should be similar to that of the Reverse .1 reads

```{r plot2, echo=FALSE}
plotQualityProfile(R1sgood[1:4])
```

On the other hand, the quality of the .2 reads should decrease earlier
```{r qplot3, echo=FALSE}
plotQualityProfile(F2sgood[1:4])
```

## Now start with the trimming of each read based on the quality we just plotted
```{r filter and trim}
filt_path <- file.path(params$folder, "/filtered") # Place filtered files in filtered/ subdirectory
filtF1s <- file.path(filt_path, paste0(good.sample.names, "_F1_filt.fastq.gz"))
filtF2s <- file.path(filt_path, paste0(good.sample.names, "_F2_filt.fastq.gz"))
out_Fs <- filterAndTrim(F1sgood, filtF1s, F2sgood, filtF2s, truncLen=c(240,160),
                      maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
                      compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE

filtR1s <- file.path(filt_path, paste0(good.sample.names, "_R1_filt.fastq.gz"))
filtR2s <- file.path(filt_path, paste0(good.sample.names, "_R2_filt.fastq.gz"))
out_Rs <- filterAndTrim(R1sgood, filtR1s, R2sgood, filtR2s, truncLen=c(240,160),
                      maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
                      compress=TRUE, multithread=TRUE)
```


```{r as tibble}
out_Fs_tibble<-tibble(file=dimnames(out_Fs)[[1]], reads.out=out_Fs[,2])
out_Rs_tibble<-tibble(file=dimnames(out_Rs)[[1]], reads.out=out_Rs[,2])

```

Now the first crucial step: learning the error rates that would be different for fwd and rev reads

```{r learning errors, echo=F}
errF1 <- learnErrors(filtF1s, multithread=TRUE)
errF2 <- learnErrors(filtF2s, multithread=TRUE)
errR1 <- learnErrors(filtR1s, multithread=TRUE)
errR2 <- learnErrors(filtR2s, multithread=TRUE)

```

Which we can plot now to see the error rates between transitions of each pair of nt
```{r plotErrors}

plotErrors(errF1, nominalQ = T)
plotErrors(errF2, nominalQ = T)
plotErrors(errR1, nominalQ = T)
plotErrors(errR2, nominalQ = T)


```

## Now go to the dereplication step

```{r dereplication, echo=F,message=FALSE}
derepF1s <- derepFastq(filtF1s, verbose=TRUE)
derepF2s <- derepFastq(filtF2s, verbose=TRUE)
derepR1s <- derepFastq(filtR1s, verbose=TRUE)
derepR2s <- derepFastq(filtR2s, verbose=TRUE)

# Name the derep-class objects by the sample names
rownames(out_Fs) <- names(derepF1s) <- names(derepF2s) <- real.sample.name$Sample

rownames(out_Rs) <- names(derepR1s) <- names(derepR2s) <- real.sample.name$Sample

```

## And finally an inference of the sample composition

```{r dadaing, message=FALSE}
dadaF1s <- dada(derepF1s, err = errF1, multithread = TRUE)
dadaF2s <- dada(derepF2s, err = errF2, multithread = TRUE)
dadaR1s <- dada(derepR1s, err = errR1, multithread = TRUE)
dadaR2s <- dada(derepR2s, err = errR2, multithread = TRUE)

```

## We are ready now to merge reads - using the denoised reads and the derep files

```{r merging pairs}

mergersF <- mergePairs(dadaF1s, derepF1s, dadaF2s, derepF2s, verbose=T)
head(mergersF[[1]])
mergersR <- mergePairs(dadaR1s, derepR1s, dadaR2s, derepR2s, verbose = T)
head(mergersR[[1]])

```

## Now we have to merge the Forward and Reverse Reads to make a unique object

Step 1 is to create sequence tables for each direction, seqtabF and seqtabR
```{r merging F and R (1)}

seqtabF <- makeSequenceTable(mergersF)

dim(seqtabF)

table(nchar(getSequences(seqtabF)))

seqtabR <- makeSequenceTable(mergersR)

dim(seqtabR)

table(nchar(getSequences(seqtabR)))
```


Step  2 is to reverse complement the reverse reads, and checking how many of the reads in F were present in R (if you get a 0 means we have done soemthing wrong). Lastly, we change the reverse sequences and add their Reverse complement instead
```{r merging F and R (2)}
reversed_sequences<-as.character(reverseComplement(DNAStringSet(colnames(seqtabR))))

summary (colnames(seqtabF) %in% reversed_sequences)

summary (reversed_sequences %in% colnames(seqtabF))

colnames(seqtabR)<-reversed_sequences

```

Step 3 does the actual merging and returns another sequence Table

```{r merging F and R (3)}

seqtab.R.df=as.data.frame(seqtabR)

final.seqtab<-data.frame(row.names = rownames(seqtab.F.df))


for (i in 1:ncol(seqtabF)) {   #for each column of the first dataframe
  
  current_seq<-colnames(seqtabF)[i]
  
  if (current_seq %in% colnames(seqtab.R.df)) { # is that column present on the second df?
    
    final.seqtab[,current_seq]<-seqtabF[,i] + seqtab.R.df[,current_seq] #if yes, the new df has the sum of reads
    
    seqtab.R.df[,current_seq]<-NULL
    #seqtab.R2.df<- seqtab.R2.df[,-current_seq] #we delete the column from the second df to speed up next search
    
    print (ncol (seqtab.R.df)) #check that is true
    
    
  } else {        # if the column is not present, then the new df is the value of the first df
    
    final.seqtab[,current_seq] <- seqtabF[,i]
    
  }
  
  
  
}
# Now cbind both dataset
final.seqtab <- as.matrix (cbind(final.seqtab,seqtab.R.df))

```

## Now get rid of the chimeras

```{r RemovingChimeras, message=F}

seqtab.nochim <- removeBimeraDenovo(final.seqtab, method="consensus", multithread=TRUE, verbose=TRUE)

dim(seqtab.nochim)  


```

We are going to keep the info in a tidyr format and save it into a csv file
```{r tidying and writing}

seqtab.nochim.df=as.data.frame(seqtab.nochim)
seqtab.nochim.df$sample=rownames(seqtab.nochim.df)

gather(seqtab.nochim.df, key=Sequence, value = nReads, -sample) %>%
  filter(nReads > 0) %>%
  write_csv(paste0(params$folder,"/DUP_table.csv"))

```


##Track the fate of all reads
```{r output_summary}

getN <- function(x) sum(getUniques(x))
track <- as.data.frame(cbind(out_Fs, out_Rs,
                             sapply(dadaF1s, getN), sapply(dadaR1s, getN),
                             sapply(mergersF, getN),sapply(mergersR, getN),
                             rowSums(seqtabF),rowSums(seqtabR),
                             rowSums(final.seqtab), rowSums(seqtab.nochim)))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input_F", "input_R", "filtered_F","filtered_R",
                     "denoised_F", "denoised_R",
                     "merged_F", "merged_R",
                     "tabled_F", "tabled_R",
                     "tabled_together", "nonchim")

write_csv(track, paste0(params$folder,"/dada2_summary.csv"))

```
